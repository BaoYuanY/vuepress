---
sidebar: auto
---


[[toc]]

# 一. Web服务器基础介绍
正常情况下单次web服务访问流程
<hr/>
![image](/image/web.png)
<hr/>

## 1.1 互联网历史发展回顾
- 1993年3月2日，中国科学院高能物理研究所租用AT&T公司的国际卫星信道建立的接入美国SLAC国家实验室的64K专线正式开通，成为我国连入Internet的第一根专线。
- 1995年马云开始创业并推出了一个web网站<<中国黄页>>，1999年创建[阿里巴巴](https://www.alibabagroup.com)，2003年5月10日创立淘宝网，2004年12月，马云创立第三方网上支付平台支付宝（蚂蚁金服旗下，共有蚂蚁金服支付宝、余额宝、招财宝、蚂蚁聚宝、网商银行、蚂蚁花呗、芝麻信用等子业务板块。），2009年开始举办双十一购物狂欢节。

::: details 历年成交额
2009年双十一：5000万元； <br>
2010年双十一：9.36亿元； <br>
2011年双十一：33.6亿元； <br>
2012年双十一：191亿元； <br>
2013年双十一：350亿元； <br>
2014年双十一：571亿元； <br>
2015年双十一：912.17亿元； <br>
2016年双十一：1207亿元元； <br>
2017年双十一：1682.69亿元； <br>
2018年双十一：2135亿元； <br>
2019年双十一：2684亿元； <br>
2020年双十一：4982亿元； <br>
2021年双十一：5403亿元； <br>
:::

2012年1月11日淘宝商城正式更名为“天猫”。2014年9月19日阿里巴巴集团于纽约证券交易所正式挂牌上市。2018年福布斯统计马云财富346亿美元。

## 1.2 web服务介绍
[Netcraft公司](https://news.netcraft.com)于1994年底在英国成立，多年一来一直致力于互联网市场以及在线安全方面的咨询服务，其中在国际上最具影响力的当属其针对网站服务器，域名解析/主机提供商，以及SSL市场所做的客观严谨的分析研究。
<hr/>
![image](/image/netcraft.png)
<hr/>

### 1.2.1 Apace-早期的web服务端
[Apache](https://www.apache.org)起初由美国的伊利诺伊大学香槟分校的国家超级计算机应用开发，目前经历了两大版本分别是1.X和2.X，其可以通过编译安装实现特定的功能，目前支持三种不同的MPM(multi-processing module)，多进程处理模块。

#### 1.2.1.1 Apache prefork模型
预派生模式，有一个主控制进程，然后生成多个子进程，使用select模型，最大并发1024，每个子进程有一个独立的线程响应用户请求，相对比较占用内存，但是比较稳定，可以设置最大和最小进程数，最古老的一种模式，也是最稳定的模式，适用于访问量不是很大的场景。
- 优点：稳定
- 缺点：大量用户访问慢，占用资源，1024个进程不适用于高并发场景

![image](/image/apache-prefork.png)

#### 1.2.1.2 Apache worker模型
一种多进程和多线程混合的模型，有一个控制进程，启动多个子进程，每个子进程里面包含固定的线程，使用线程来处理请求，当线程不够使用的时候会再启动一个新的子进程，然后在进程里面再启动线程处理请求，由于其使用了线程处理请求，因此可以承受更高的并发。
- 优点：相比prefork占用的内存较少，可用同时处理更多的请求
- 缺点：使用keepalive的长链接方式，某个线程会一直一直被占据，即使没有传输数据，也需要一直等待到超时才会被释放。如果过多线程，被这样占据，也会导致在高并发场景下的无服务线程可用。（该问题在prefork模式下，同样会发生）

![image](/image/apache-worker.png)

#### 1.2.1.3 Apache event模型
Apache中最新的模式，2012年发布的 apache 2.4.X 系列正式支持event模型，属于事件驱动模型（epoll），每个进程响应多个请求，在现在版本里的已经是最稳定可用的模型。他和worker模式很像，最大的区别在于，它解决了keepalive场景下，长期被占用的线程的资源浪费问题（某写线程因为被keepalive，空挂在那里等待，中间几乎没有请求来往，甚至等待超时）。event MPM中，会有一个专门的线程来管理这些keepalive类型的线程，当有真实请求过来的时候，将请求传递给服务线程，执行完毕后，又允许它释放。这样增强了高并发场景下的请求处理能力。
- 优点：单线程响应多请求，占据更少的内存，高并发下表现更优秀，会有一个专门的线程来管理keep-alive类型的线程，当有真实请求过来的时候，将请求传递给服务线程，执行完毕后，又允许它释放
- 缺点：没有线程安全控制

![image](/image/apache-event.png)

> 监听线程用于向工作线程分配任务并和客户端保持会话连接，超时之后监听线程会删除该socket，工作线程只处理用户请求，处理完之后将会话保持交于监听线程，自己去处理新的请求，不再负责会话保持。

### 1.2.2 Nginx-高性能的web服务端
[Nginx](https://www.nginx.org)是由1994年毕业于俄罗斯国立莫斯科鲍曼科技大学的同学为俄罗斯 rambler.ru 公司开发的，开发工作从最早从2002年开始，第一次公开发布时间是2004年10月4日，版本号是0.1.0。

Nginx历经十几年的迭代更新（[https://nginx.org/en/CHANGES](https://nginx.org/en/CHANGES)），目前功能已经非常完善且运行稳定，另外Nginx的版本分为开发版、稳定版和过期版，Nginx以功能丰富著称，它既可以作为http服务器，也可以作为反向代理服务器或者邮件服务器，能够快速的响应静态网页的请求，支持FastCGI/SSL/Virtual Host/URL Rwrite/Gzip/HTTP Basic Auth/http或者TCP的负载均衡（1.9版本以上且开启stream模块）等功能，并且支持第三方的功能扩展。

为什么使用Nginx：天猫 淘宝 小米 163 京东 新浪等一线互联网公司都在用Nginx或者进行二次开发

基于Nginx的访问流程如下：

![image](/image/nginx-flow.png)

### 1.2.3 用户访问体验统计
互联网存在用户速度体验的1-3-10原则，即1秒最优，1-3秒较优，3-10秒较慢，10秒以上用户无法接受。用户放弃一个产品的代价很低，只是换一个URL而已。

- 全球最大搜索引擎Google：慢500ms=20% 将放弃访问
- 全球最大的电商零售网站亚马逊：慢100ms=1% 将放弃交易

### 1.2.4 性能影响
有很多研究表明，性能对用户的行为有很大的影响：79%的用户表示不太能再次打开一个缓慢的网站，47%的用户期望网页能在2秒钟以内加载，40%的用户表示如果加载时间超过3秒钟就会放弃这个网站。页面加载时间延迟1秒可能导致转换损失7%，页面浏览量减少11%。8秒定律：用户访问一个网站时，如果等待网页打开的时间超过8秒，会有超过30%的用户放弃等待

#### 1.2.4.1 影响用户体验的几个因素
据说马云在刚开始创业在给客户演示时，打开一个网站花了两个多小时。

1. 客户端硬件配置 
2. 客户端网络速率 
3. 客户端与服务端距离 
4. 服务端网络速率 
5. 服务端硬件配置 
6. 服务端架构设计 
7. 服务端应用程序工作模式 
8. 服务端并发数量 
9. 服务端响应文件大小及数量 
10. 服务端I/O压力

#### 1.2.4.2 应用程序工作模式
```
httpd MPM（Multi-Processing Module，多进程处理模块）模式：
prefork：进程模型，两级结构，主进程master负责生成子进程，每个子进程负责响应一个请求
worker：线程模型，三级结构，主进程master负责生成子进程，每个子进程负责生成多个线程，每个线程响应一个请求
event：线程模型，三级结构,主进程master负责生成子进程，每个子进程生成多个线程，每个线程响应一个请求，但是增加了一个监听线程，用于解决在设置了keep-alived场景下线程的空等待问题。

Nginx（Master+Worker）模式：
主进程
工作进程 #直接处理客户的请求

线程验证方式：
#cat /proc/PID/status
#pstree -p PID
```

#### 1.2.4.3 服务端 I/O
I/O在计算机中指Input/Output， IOPS (Input/Output Per Second)即每秒的输入输出量(或读写次数)，是衡量磁盘性能的主要指标之一。IOPS是指的是在单位时间内系统能处理的I/O请求数量，一般以每秒处理的I/O请求数量为单位，I/O请求通常为读或写数据操作请求。

```
机械磁盘的寻道时间、旋转延迟和数据传输时间：
寻道时间：是指磁头移动到正确的磁道上所花费的时间，寻道时间越短则I/O处理就越快，目前磁盘的寻道时间一般在3-15毫秒左右。
旋转延迟：是指将磁盘片旋转到数据所在的扇区到磁头下面所花费的时间，旋转延迟取决于磁盘的转速，通常使用磁盘旋转一周所需要时间的1/2之一表示，比如7200转的磁盘平均训传延迟大约为60*1000/7200/2=4.17毫秒，公式的意思为 （每分钟60秒*1000毫秒每秒/7200转每分钟/2），如果是15000转的则为60*1000/15000/2=2毫秒。
数据传输时间：指的是读取到数据后传输数据的时间，主要取决于传输速率，这个值等于数据大小除以传输速率，
目前的磁盘接口每秒的传输速度可以达到600MB，因此可以忽略不计。
常见的机械磁盘平均寻道时间值：
7200转/分的磁盘平均物理寻道时间：9毫秒
10000转/分的磁盘平均物理寻道时间：6毫秒
15000转/分的磁盘平均物理寻道时间：4毫秒

常见磁盘的平均延迟时间：
7200转的机械盘平均延迟：60*1000/7200/2 = 4.17ms
10000转的机械盘平均延迟：60*1000/10000/2 = 3ms
15000转的机械盘平均延迟：60*1000/15000/2 = 2ms

每秒最大IOPS的计算方法：
7200转的磁盘IOPS计算方式：1000毫秒/(9毫秒的寻道时间+4.17毫秒的平均旋转延迟时间)=1000/13.13=75.9 IOPS
10000转的磁盘的IOPS计算方式：1000毫秒/(6毫秒的寻道时间+3毫秒的平均旋转延迟时间)=1000/9=111 IOPS
15000转的磁盘的IOPS计算方式：15000毫秒/(4毫秒的寻道时间+2毫秒的平均旋转延迟时间)=1000/6=166.6 IOPS
```
一次完整的I/O是用户空间的进程数据与内核空间的内核数据的报文的完整交换，但是由于内核空间与用户空间是严格隔离的，所以其数据交换过程中不能由用户空间的进程直接调用内核空间的内存数据，而是需要经历一次从内核空间中的内存数据copy到用户空间的进程内存当中，所以简单说I/O就是把数据从内核空间中的内存数据复制到用户空间中进程的内存当中。

而网络通信就是网络协议栈到用户空间进程的IO就是网络IO

![image](/image/network-io.png)

磁盘I/O是进程向内核发起系统调用，请求磁盘上的某个资源比如是文件或者是图片，然后内核通过相应的驱动程序将目标图片加载到内核的内存空间，加载完成之后把数据从内核内存再复制给进程内存，如果是比较大的数据也需要等待时间。

每次IO，都要经由两个阶段：
1. 将数据从磁盘文件先加载至内核内存空间（缓冲区），此步骤需要等待数据准备完成，时间较长
2. 将数据从内核缓冲区复制到用户空间的进程的内存中，时间较短

## 1.3 系统 I/O 模型
**同步/异步：关注的是事件处理的消息通信机制，即在等待一件事情的处理结果时，被调用者是否提供完成通知。**

- 同步：synchronous，调用者等待被调用者返回消息后才能继续执行，如果被调用者不提供消息返回则为同步，同步需要调用者主动询问事情是否处理完成。
- 异步：asynchronous，被调用者通过状态、通知或回调机制主动通知调用者被调用者的运行状态

`同步` 进程发出请求调用后，等内核返回响应以后才继续下一个请求，即如果内核一直不返回数据，那么进程就一直等

`异步` 进程发出请求调用后，不等内核返回响应，接着处理下一个请求,Nginx是异步的

**阻塞/非阻塞：关注调用者在等待结果返回之前所处的状态**

- 阻塞：blocking，指IO操作需要彻底完成后才返回到用户空间，调用结果返回之前，调用者被挂起，干不了别的事情。
- 非阻塞：nonblocking，指IO操作被调用后立即返回给用户一个状态值，无需等到IO操作彻底完成，最终的调用结果返回之前，调用者不会被挂起，可以去做别的事情。

## 1.4 网络 I/O 模型
阻塞型、非阻塞型、复用型、信号驱动型、异步

### 1.4.1 同步阻塞型IO模型（blocking IO）
阻塞IO模型是最简单的IO模型，用户线程在内核进行IO操作时被阻塞 用户线程通过系统调用read发起IO读操作，由用户空间转到内核空间。内核等到数据包到达后，然后将接收的数据拷贝到用户空间，完成read操作 用户需要等待read将数据读取到buffer后，才继续处理接收的数据。整个IO请求的过程中，用户线程是被阻塞的，这导致用户在发起IO请求时，不能做任何事情，对CPU的资源利用率不够。
- 优点：程序简单，在阻塞等待数据期间进程/线程挂起，基本不会占用 CPU 资源
- 缺点：每个连接需要独立的进程/线程单独处理，当并发请求量大时为了维护程序，内存、线程切换开销较大，apache 的prefork使用的是这种模式。

> 同步阻塞：程序向内核发送IO请求后一直等待内核响应，如果内核处理请求的IO操作不能立即返回,则进程将一直等待并不再接受新的请求，并由进程轮训查看IO是否完成，完成后进程将IO结果返回给Client，在IO没有返回期间进程不能接受其他客户的请求，而且是有进程自己去查看IO是否完成，这种方式简单，但是比较慢，用的比较少。

![image](/image/blocking-io.png)

### 1.4.2 同步非阻塞型 I/O 模型（nonblocking IO）

用户线程发起IO请求时立即返回。但并未读取到任何数据，用户线程需要不断地发起IO请求，直到数据到达后，才真正读取到数据，继续执行。即 “轮询”机制存在两个问题：如果有大量文件描述符都要等，那么就得一个一个的read。这会带来大量的Context Switch（read是系统调用，每调用一次就得在用户态和核心态切换一次）。轮询的时间不好把握。这里是要猜多久之后数据才能到。等待时间设的太长，程序响应延迟就过大；设的太短，就会造成过于频繁的重试，干耗CPU而已，是比较浪费CPU的方式，一般很少直接使用这种模型，而是在其他IO模型中使用非阻塞IO这一特性。

> 同步非阻塞：程序向内核发送请IO求后一直等待内核响应，如果内核处理请求的IO操作不能立即返回IO结果，进程将不再等待，而且继续处理其他请求，但是仍然需要进程隔一段时间就要查看内核IO是否完成。

![img.png](/image/nonblocking-io.png)

### 1.4.3 IO多路复用型（IO multiplexing）

IO multiplexing 就是我们所说的select，poll，epoll，有些地方也称这种IO方式为 event driven IO。
select/poll/epoll的好处就在于单个process就可以同时处理多个网络连接的IO。它的基本原理就是select，poll，epoll这个function会不断的轮询所负责的socket，当某个socket有数据到达了，就通知用户进程。当用户进程调用了select，那么整个进程就会被block，而同时，kernel会“监视”所有select负责的socket，当任何一个socket中的数据准备好了，select就会返回。这个时候用户进程再调用read操作，将数据从kernel拷贝到用户进程。

> Apache prefork是此模式的主进程+多进程/单线程+select，work是主进程+多进程/多线程+poll模式










# 二. Nginx基础
## 2.1 Nginx功能介绍

























































